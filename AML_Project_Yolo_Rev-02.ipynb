{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers import LeakyReLU, UpSampling1D, Input, Reshape, Activation, Lambda, AveragePooling1D\n",
    "from keras.layers import Convolution2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Dropout, Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "import random\n",
    "\n",
    "# From pypng\n",
    "import png\n",
    "#from sklearn.p\n",
    "\n",
    "FONTSIZE = 18\n",
    "FIGURE_SIZE = (10,4)\n",
    "FIGURE_SIZE2 = (10,10)\n",
    "\n",
    "# Configure parameters\n",
    "plt.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "####################################\n",
    "# \n",
    "import re\n",
    "\n",
    "##################\n",
    "# Default tick label size\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for generating list of images of respective parts.\n",
    "def make_df(file, coloumn_name, code, new_coloumn_entry):\n",
    "    image_names = []\n",
    "    check_for = file[coloumn_name] == code\n",
    "    file_data = file[check_for]\n",
    "    file_data['Lesion_typename'] = new_coloumn_entry\n",
    "    return(file_data)\n",
    "\n",
    "#Function for generating training, validation and test sets list of images of respective parts.\n",
    "def sets(image_names):\n",
    "    train_length = len(image_names) * 0.7\n",
    "    int_train_length = int(train_length)\n",
    "    val_length = int_train_length + len(image_names) * 0.15\n",
    "    int_val_length = int(val_length)\n",
    "    trainset = image_names[:int_train_length]\n",
    "    valset = image_names[int_train_length:int_val_length]\n",
    "    testset = image_names[int_val_length:]\n",
    "    return (trainset, valset, testset)\n",
    "\n",
    "#Function for generating lists of imagenames and labels for trainset, valset and testset.\n",
    "def make_list(Full_list, data_length):\n",
    "    image_name = []\n",
    "    image_label = []\n",
    "    #Storing annotated image file names in a list (image_name).\n",
    "    for i in range (data_length):\n",
    "        image_name.append(Full_list['File_name'].values[i])\n",
    "    #Storing annotated image label names in a list (image_label).\n",
    "    for i in range (data_length):\n",
    "        image_label.append(Full_list['Coarse_lesion_type'].values[i])\n",
    "    return (image_name, image_label)\n",
    "\n",
    "#Function for reading each image file and returning a 3-dimensional array.\n",
    "def Read_image(image_name):\n",
    "    read_image = png.Reader(image_name)\n",
    "    image_copy = read_image.read()\n",
    "    image_in_2d = np.vstack(map(np.uint8, image_copy[2]))\n",
    "    image_in_3d = np.reshape(image_in_2d, (image_copy[0],image_copy[1],image_copy[3]['planes'])) / 512.0\n",
    "    return image_in_3d\n",
    "\n",
    "#Function for reading each image file from given directory using given image name list and returning a array.\n",
    "def Image_directory(directory, image_name):\n",
    "    print(directory, image_name)\n",
    "    #Get all of the file names\n",
    "    all_images = sorted(os.listdir(directory))\n",
    "    list_of_images = [Read_image(directory + \"/\" + i) for i in all_images if re.search(image_name, i) ]    \n",
    "    return np.array(list_of_images, dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which takes measurement coordinates from csv file and compute mid-point of bounding box and height and width\n",
    "def target_point(Measurement_coordinates):\n",
    "    split_Mesur_list = []\n",
    "    x_pt = []\n",
    "    y_pt = []\n",
    "    \n",
    "    split_Mesur_list = Measurement_coordinates.split(', ')\n",
    "    x_ind = [0, 2, 4, 6]\n",
    "    y_ind = [1, 3, 5, 7]\n",
    "    \n",
    "    #List for respective coordinate points.\n",
    "    for i in x_ind:\n",
    "        x_pt.append(float(split_Mesur_list[i]))\n",
    "    for j in y_ind:\n",
    "        y_pt.append(float(split_Mesur_list[j]))\n",
    "    \n",
    "    #Height and width of bounding box\n",
    "    height = max(y_pt) - min(y_pt)\n",
    "    width = max(x_pt) - min(x_pt)\n",
    "    \n",
    "    #Mid point estimation.\n",
    "    x_mid_1 = (x_pt[0] + x_pt[1])/2\n",
    "    y_mid_1 = (y_pt[0] + y_pt[1])/2\n",
    "    x_mid_2 = (x_pt[2] + x_pt[3])/2\n",
    "    y_mid_2 = (y_pt[2] + y_pt[3])/2\n",
    "    x_mid = (x_mid_1 + x_mid_2)/2\n",
    "    y_mid = (y_mid_1 + y_mid_2)/2\n",
    "    \n",
    "    return x_mid, y_mid, height, width\n",
    "\n",
    "#Function which takes measurement coordinates and grid size in number of pixels and returns target label of respective shape.\n",
    "def gen_target(Measurement_coordinates, grid_size = 16):\n",
    "    #Computing mid point, height and width of bounding box.\n",
    "    x_mid, y_mid, height, width = target_point(Measurement_coordinates)\n",
    "    #Total number of grids, using given grid size.\n",
    "    grids = int(512/grid_size)\n",
    "    \n",
    "    #Locating grid which has midpoint.\n",
    "    x_grid = int(x_mid/grid_size)\n",
    "    y_grid = int(y_mid/grid_size)\n",
    "\n",
    "    #mid points with respect to each grid\n",
    "    x_mid_grid = (x_mid/grid_size) - x_grid\n",
    "    y_mid_grid = (y_mid/grid_size) - y_grid    \n",
    "\n",
    "    \n",
    "    #initializing target label as all zeros.\n",
    "    target = np.zeros((grids,grids,5))\n",
    "    #Defining and filling up list with \"Pc\", \"bx\", \"by\", \"bh\", and \"bw\"\n",
    "    coord_list = []\n",
    "    coord_list.append(1)\n",
    "    coord_list.append(x_mid_grid)\n",
    "    coord_list.append(y_mid_grid)\n",
    "    coord_list.append(height)\n",
    "    coord_list.append(width)\n",
    "    \n",
    "    #mid point located grid is filled with the above information.\n",
    "    for i in range(len(coord_list)):\n",
    "        target[x_grid][y_grid][i] = coord_list[i]\n",
    "    \n",
    "    return target\n",
    "\n",
    "#Function for generating target labels for trainset, valset and testset.\n",
    "def make_yolo(inlist, grid_size):\n",
    "    image_name = []\n",
    "    yolo_label = []\n",
    "    data_length = inlist.shape[0]\n",
    "    #Storing annotated image file names in a list (image_name).\n",
    "    for i in range (data_length):\n",
    "        image_name.append(inlist['File_name'].values[i])\n",
    "    #Storing annotated image label names in a list (image_label).\n",
    "    for i in range (data_length):\n",
    "        Measurement_coordinates = inlist['Measurement_coordinates'].values[i]\n",
    "        yolo_label.append(gen_target(Measurement_coordinates, grid_size))\n",
    "    return (image_name, yolo_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "me, you = make_yolo(trainset_Bone, 16)\n",
    "\n",
    "#trainset_Bone.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Reading file with file name and labels.\n",
    "\n",
    "#Storing the images in directory.\n",
    "directory = '/home2/potd0000/project/Key_slices/'\n",
    "\n",
    "#data information extraction from csv file\n",
    "Entire_image_list = pd.read_csv(r'/home2/potd0000/project/Dl_info.csv')\n",
    "#Removing all other coloumns and only selecting Filename, Coarse_lesion_type and, Image_size to be there in dataframe.\n",
    "list_filename_n_type = Entire_image_list[['File_name', 'Coarse_lesion_type', 'Image_size', 'Measurement_coordinates', 'Bounding_boxes', 'Lesion_diameters_Pixel_', 'Normalized_lesion_location']]\n",
    "\n",
    "#Eliminating 40 image names which is not of size '512 x 512'\n",
    "check_for_size = list_filename_n_type['Image_size'] == '512, 512'\n",
    "list_filename_n_type = list_filename_n_type[check_for_size]\n",
    "\n",
    "\n",
    "Bone_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 1, 'Bone')\n",
    "Abdomen_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 2, 'Abdomen')\n",
    "Mediastinum_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 3, 'Mediastinum')\n",
    "Liver_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 4, 'Liver')\n",
    "Lung_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 5, 'Lung')\n",
    "Kidney_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 6, 'Kidney')\n",
    "Soft_tissue_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 7, 'Soft_tissue')\n",
    "Pelvis_image_names = make_df(list_filename_n_type, 'Coarse_lesion_type', 8, 'Pelvis')\n",
    "\n",
    "\n",
    "trainset_Bone, valset_Bone, testset_Bone = sets(Bone_image_names)\n",
    "trainset_Abdomen, valset_Abdomen, testset_Abdomen = sets(Abdomen_image_names)\n",
    "trainset_Mediastinum, valset_Mediastinum, testset_Mediastinum = sets(Mediastinum_image_names)\n",
    "trainset_Liver, valset_Liver, testset_Liver = sets(Liver_image_names)\n",
    "trainset_Lung, valset_Lung, testset_Lung = sets(Lung_image_names)\n",
    "trainset_Kidney, valset_Kidney, testset_Kidney = sets(Kidney_image_names)\n",
    "trainset_Soft_tissue, valset_Soft_tissue, testset_Soft_tissue = sets(Soft_tissue_image_names)\n",
    "trainset_Pelvis, valset_Pelvis, testset_Pelvis = sets(Pelvis_image_names)\n",
    "\n",
    "training_name_df = pd.DataFrame(trainset_Bone)\n",
    "training_name_df = training_name_df.append(trainset_Abdomen)\n",
    "training_name_df = training_name_df.append(trainset_Mediastinum)\n",
    "training_name_df = training_name_df.append(trainset_Liver)\n",
    "training_name_df = training_name_df.append(trainset_Lung)\n",
    "training_name_df = training_name_df.append(trainset_Kidney)\n",
    "training_name_df = training_name_df.append(trainset_Soft_tissue)\n",
    "training_name_df = training_name_df.append(trainset_Pelvis)\n",
    "\n",
    "validation_name_df = pd.DataFrame(valset_Bone)\n",
    "validation_name_df = validation_name_df.append(valset_Abdomen)\n",
    "validation_name_df = validation_name_df.append(valset_Mediastinum)\n",
    "validation_name_df = validation_name_df.append(valset_Liver)\n",
    "validation_name_df = validation_name_df.append(valset_Lung)\n",
    "validation_name_df = validation_name_df.append(valset_Kidney)\n",
    "validation_name_df = validation_name_df.append(valset_Soft_tissue)\n",
    "validation_name_df = validation_name_df.append(valset_Pelvis)\n",
    "\n",
    "testing_name_df = pd.DataFrame(testset_Bone)\n",
    "testing_name_df = testing_name_df.append(testset_Abdomen)\n",
    "testing_name_df = testing_name_df.append(testset_Mediastinum)\n",
    "testing_name_df = testing_name_df.append(testset_Liver)\n",
    "testing_name_df = testing_name_df.append(testset_Lung)\n",
    "testing_name_df = testing_name_df.append(testset_Kidney)\n",
    "testing_name_df = testing_name_df.append(testset_Soft_tissue)\n",
    "testing_name_df = testing_name_df.append(testset_Pelvis)\n",
    "\n",
    "trainset_length = len(training_name_df)\n",
    "valset_length = len(validation_name_df)\n",
    "testset_length = len(testing_name_df)\n",
    "\n",
    "\n",
    "training_image_name, training_image_label = make_list(training_name_df, trainset_length)\n",
    "validation_image_name, validation_image_label = make_list(validation_name_df, valset_length)\n",
    "testing_image_name, testing_image_label = make_list(testing_name_df, testset_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_train_bone_ins, yolo_train_bone_outs = make_yolo(trainset_Bone, 16)\n",
    "yolo_val_bone_ins, yolo_val_bone_outs = make_yolo(valset_Bone, 16)\n",
    "yolo_test_bone_ins, yolo_test_bone_outs = make_yolo(testset_Bone, 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/potd0000/project/Key_slices/ 000010_02_02_100.png\n",
      "/home2/potd0000/project/Key_slices/ 000020_02_01_062.png\n",
      "/home2/potd0000/project/Key_slices/ 000122_04_02_150.png\n",
      "/home2/potd0000/project/Key_slices/ 000193_01_02_469.png\n",
      "/home2/potd0000/project/Key_slices/ 000193_02_02_477.png\n",
      "/home2/potd0000/project/Key_slices/ 000193_03_01_458.png\n",
      "/home2/potd0000/project/Key_slices/ 000207_05_02_444.png\n",
      "/home2/potd0000/project/Key_slices/ 000207_06_01_089.png\n",
      "/home2/potd0000/project/Key_slices/ 000207_06_02_444.png\n",
      "/home2/potd0000/project/Key_slices/ 000207_06_02_443.png\n",
      "/home2/potd0000/project/Key_slices/ 000207_07_01_223.png\n",
      "/home2/potd0000/project/Key_slices/ 000207_07_01_444.png\n",
      "/home2/potd0000/project/Key_slices/ 000250_02_01_094.png\n",
      "/home2/potd0000/project/Key_slices/ 000250_03_01_093.png\n",
      "/home2/potd0000/project/Key_slices/ 000280_03_02_501.png\n",
      "/home2/potd0000/project/Key_slices/ 000281_03_01_291.png\n",
      "/home2/potd0000/project/Key_slices/ 000281_04_01_022.png\n",
      "/home2/potd0000/project/Key_slices/ 000281_05_01_113.png\n",
      "/home2/potd0000/project/Key_slices/ 000286_02_01_022.png\n",
      "/home2/potd0000/project/Key_slices/ 000293_04_02_055.png\n",
      "/home2/potd0000/project/Key_slices/ 000293_05_01_017.png\n",
      "/home2/potd0000/project/Key_slices/ 000293_05_01_110.png\n",
      "/home2/potd0000/project/Key_slices/ 000293_06_01_014.png\n",
      "/home2/potd0000/project/Key_slices/ 000293_06_01_098.png\n",
      "/home2/potd0000/project/Key_slices/ 000293_06_01_107.png\n",
      "/home2/potd0000/project/Key_slices/ 000328_08_03_167.png\n",
      "/home2/potd0000/project/Key_slices/ 000363_02_02_462.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_01_02_107.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_01_02_121.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_02_02_111.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_02_02_125.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_03_01_110.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_04_01_106.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_04_01_093.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_05_01_140.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_05_01_126.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_05_01_073.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_06_02_119.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_06_02_104.png\n",
      "/home2/potd0000/project/Key_slices/ 000367_06_02_050.png\n",
      "/home2/potd0000/project/Key_slices/ 000374_03_02_471.png\n",
      "/home2/potd0000/project/Key_slices/ 000374_04_02_461.png\n",
      "/home2/potd0000/project/Key_slices/ 000410_02_02_069.png\n",
      "/home2/potd0000/project/Key_slices/ 000439_04_01_019.png\n",
      "/home2/potd0000/project/Key_slices/ 000492_02_02_419.png\n",
      "/home2/potd0000/project/Key_slices/ 000503_02_01_404.png\n",
      "/home2/potd0000/project/Key_slices/ 000612_01_01_402.png\n",
      "/home2/potd0000/project/Key_slices/ 000612_02_01_395.png\n",
      "/home2/potd0000/project/Key_slices/ 000612_03_01_400.png\n",
      "/home2/potd0000/project/Key_slices/ 000760_09_03_378.png\n",
      "/home2/potd0000/project/Key_slices/ 000775_02_02_102.png\n",
      "/home2/potd0000/project/Key_slices/ 000818_04_01_108.png\n",
      "/home2/potd0000/project/Key_slices/ 000961_04_03_184.png\n",
      "/home2/potd0000/project/Key_slices/ 000961_04_03_346.png\n",
      "/home2/potd0000/project/Key_slices/ 001027_03_01_006.png\n",
      "/home2/potd0000/project/Key_slices/ 001079_03_03_140.png\n",
      "/home2/potd0000/project/Key_slices/ 001152_05_02_402.png\n",
      "/home2/potd0000/project/Key_slices/ 001170_08_04_470.png\n",
      "/home2/potd0000/project/Key_slices/ 001205_03_01_162.png\n",
      "/home2/potd0000/project/Key_slices/ 001209_01_01_139.png\n",
      "/home2/potd0000/project/Key_slices/ 001209_02_01_133.png\n",
      "/home2/potd0000/project/Key_slices/ 001209_03_01_131.png\n",
      "/home2/potd0000/project/Key_slices/ 001290_05_02_312.png\n",
      "/home2/potd0000/project/Key_slices/ 001290_05_02_477.png\n",
      "/home2/potd0000/project/Key_slices/ 001290_05_02_646.png\n",
      "/home2/potd0000/project/Key_slices/ 001300_02_01_029.png\n",
      "/home2/potd0000/project/Key_slices/ 001420_01_02_437.png\n",
      "/home2/potd0000/project/Key_slices/ 001421_02_01_248.png\n",
      "/home2/potd0000/project/Key_slices/ 001421_03_02_262.png\n",
      "/home2/potd0000/project/Key_slices/ 001477_01_01_079.png\n",
      "/home2/potd0000/project/Key_slices/ 001477_02_02_385.png\n",
      "/home2/potd0000/project/Key_slices/ 001477_02_02_476.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_01_02_060.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_02_02_047.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_02_02_050.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_02_02_185.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_02_02_253.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_02_02_513.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_03_02_052.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_03_02_049.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_03_02_185.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_03_02_256.png\n",
      "/home2/potd0000/project/Key_slices/ 001564_03_02_512.png\n",
      "/home2/potd0000/project/Key_slices/ 001594_03_01_496.png\n",
      "/home2/potd0000/project/Key_slices/ 001594_03_01_460.png\n",
      "/home2/potd0000/project/Key_slices/ 001676_04_03_077.png\n",
      "/home2/potd0000/project/Key_slices/ 001676_04_03_577.png\n",
      "/home2/potd0000/project/Key_slices/ 001693_02_01_136.png\n",
      "/home2/potd0000/project/Key_slices/ 001751_04_03_521.png\n",
      "/home2/potd0000/project/Key_slices/ 001761_01_01_448.png\n",
      "/home2/potd0000/project/Key_slices/ 001761_01_01_473.png\n",
      "/home2/potd0000/project/Key_slices/ 001797_01_01_096.png\n",
      "/home2/potd0000/project/Key_slices/ 001797_01_02_453.png\n",
      "/home2/potd0000/project/Key_slices/ 001965_01_02_481.png\n",
      "/home2/potd0000/project/Key_slices/ 001965_01_02_600.png\n",
      "/home2/potd0000/project/Key_slices/ 002057_01_02_077.png\n",
      "/home2/potd0000/project/Key_slices/ 002096_01_01_104.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_08_02_354.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_08_02_491.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_08_02_549.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_10_02_354.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_10_02_506.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_10_02_487.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_10_02_550.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_16_02_003.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_16_02_090.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_17_01_011.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_17_01_087.png\n",
      "/home2/potd0000/project/Key_slices/ 002110_17_01_324.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_06_01_112.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_07_01_057.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_07_01_069.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_07_01_013.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_07_01_208.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_07_01_165.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_08_02_315.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_10_01_161.png\n",
      "/home2/potd0000/project/Key_slices/ 002153_10_01_322.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_01_01_098.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_01_02_486.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_02_01_490.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_02_01_492.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_03_01_474.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_04_01_479.png\n",
      "/home2/potd0000/project/Key_slices/ 002203_04_02_480.png\n",
      "/home2/potd0000/project/Key_slices/ 002256_02_03_174.png\n",
      "/home2/potd0000/project/Key_slices/ 002256_02_03_263.png\n",
      "/home2/potd0000/project/Key_slices/ 002317_01_02_074.png\n",
      "/home2/potd0000/project/Key_slices/ 002317_02_02_066.png\n",
      "/home2/potd0000/project/Key_slices/ 002366_01_02_068.png\n",
      "/home2/potd0000/project/Key_slices/ 002366_01_02_139.png\n",
      "/home2/potd0000/project/Key_slices/ 002366_01_02_301.png\n",
      "/home2/potd0000/project/Key_slices/ 002414_04_01_061.png\n",
      "/home2/potd0000/project/Key_slices/ 002511_01_02_168.png\n",
      "/home2/potd0000/project/Key_slices/ 002511_02_03_159.png\n",
      "/home2/potd0000/project/Key_slices/ 002628_01_01_256.png\n",
      "/home2/potd0000/project/Key_slices/ 002639_06_01_189.png\n",
      "/home2/potd0000/project/Key_slices/ 002741_01_03_481.png\n",
      "/home2/potd0000/project/Key_slices/ 002809_02_02_400.png\n",
      "/home2/potd0000/project/Key_slices/ 002809_03_01_079.png\n",
      "/home2/potd0000/project/Key_slices/ 002809_04_02_411.png\n",
      "/home2/potd0000/project/Key_slices/ 002918_03_01_031.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_01_02_163.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_01_02_112.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_01_02_180.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_02_02_164.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_02_02_105.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_02_02_146.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_02_02_085.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_03_02_196.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_03_02_169.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_03_02_128.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_04_02_169.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_04_02_188.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_04_02_105.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_04_02_125.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_05_02_144.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_05_02_180.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_05_02_111.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_05_02_156.png\n",
      "/home2/potd0000/project/Key_slices/ 002958_05_02_092.png\n",
      "/home2/potd0000/project/Key_slices/ 002970_01_02_191.png\n",
      "/home2/potd0000/project/Key_slices/ 002970_02_02_181.png\n",
      "/home2/potd0000/project/Key_slices/ 002993_01_02_474.png\n",
      "/home2/potd0000/project/Key_slices/ 003185_06_03_153.png\n",
      "/home2/potd0000/project/Key_slices/ 003185_06_03_142.png\n",
      "/home2/potd0000/project/Key_slices/ 003185_06_03_351.png\n",
      "/home2/potd0000/project/Key_slices/ 003185_06_03_467.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_01_02_320.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_01_02_423.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_01_02_420.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_02_03_319.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(172, 512, 512, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_image_data_list = []\n",
    "\n",
    "for names in yolo_train_bone_ins:\n",
    "    train_image_data_list.extend(Image_directory(directory, names))\n",
    "input_train_image = np.array(train_image_data_list)\n",
    "input_train_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('yolo_bone_input_train_image_data', input_train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_bone_input_train_image_saved = np.load('yolo_bone_input_train_image_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/potd0000/project/Key_slices/ 003209_03_03_320.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_05_02_261.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_05_02_329.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_06_01_267.png\n",
      "/home2/potd0000/project/Key_slices/ 003209_06_01_334.png\n",
      "/home2/potd0000/project/Key_slices/ 003210_01_01_129.png\n",
      "/home2/potd0000/project/Key_slices/ 003226_01_02_528.png\n",
      "/home2/potd0000/project/Key_slices/ 003285_02_02_451.png\n",
      "/home2/potd0000/project/Key_slices/ 003327_01_02_177.png\n",
      "/home2/potd0000/project/Key_slices/ 003347_02_01_020.png\n",
      "/home2/potd0000/project/Key_slices/ 003347_02_01_084.png\n",
      "/home2/potd0000/project/Key_slices/ 003347_02_01_123.png\n",
      "/home2/potd0000/project/Key_slices/ 003406_01_01_103.png\n",
      "/home2/potd0000/project/Key_slices/ 003406_01_01_094.png\n",
      "/home2/potd0000/project/Key_slices/ 003420_01_01_395.png\n",
      "/home2/potd0000/project/Key_slices/ 003420_02_01_412.png\n",
      "/home2/potd0000/project/Key_slices/ 003420_02_01_372.png\n",
      "/home2/potd0000/project/Key_slices/ 003420_02_01_404.png\n",
      "/home2/potd0000/project/Key_slices/ 003497_04_01_050.png\n",
      "/home2/potd0000/project/Key_slices/ 003497_04_02_050.png\n",
      "/home2/potd0000/project/Key_slices/ 003516_03_02_185.png\n",
      "/home2/potd0000/project/Key_slices/ 003524_01_01_022.png\n",
      "/home2/potd0000/project/Key_slices/ 003544_01_02_159.png\n",
      "/home2/potd0000/project/Key_slices/ 003544_01_02_163.png\n",
      "/home2/potd0000/project/Key_slices/ 003544_02_02_188.png\n",
      "/home2/potd0000/project/Key_slices/ 003544_02_02_186.png\n",
      "/home2/potd0000/project/Key_slices/ 003557_01_01_003.png\n",
      "/home2/potd0000/project/Key_slices/ 003557_01_01_023.png\n",
      "/home2/potd0000/project/Key_slices/ 003557_01_01_100.png\n",
      "/home2/potd0000/project/Key_slices/ 003565_01_02_115.png\n",
      "/home2/potd0000/project/Key_slices/ 003565_01_02_275.png\n",
      "/home2/potd0000/project/Key_slices/ 003565_01_02_406.png\n",
      "/home2/potd0000/project/Key_slices/ 003565_02_01_017.png\n",
      "/home2/potd0000/project/Key_slices/ 003565_02_02_125.png\n",
      "/home2/potd0000/project/Key_slices/ 003565_02_02_412.png\n",
      "/home2/potd0000/project/Key_slices/ 003571_01_01_444.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 512, 512, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val_image_data_list = []\n",
    "\n",
    "for names in yolo_val_bone_ins:\n",
    "    val_image_data_list.extend(Image_directory(directory, names))\n",
    "input_val_image = np.array(val_image_data_list)\n",
    "input_val_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('yolo_bone_input_val_image_data', input_val_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_bone_input_val_image_saved = np.load('yolo_bone_input_val_image_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/potd0000/project/Key_slices/ 003663_02_03_117.png\n",
      "/home2/potd0000/project/Key_slices/ 003722_02_02_227.png\n",
      "/home2/potd0000/project/Key_slices/ 003722_02_03_477.png\n",
      "/home2/potd0000/project/Key_slices/ 003722_02_03_417.png\n",
      "/home2/potd0000/project/Key_slices/ 003722_03_01_225.png\n",
      "/home2/potd0000/project/Key_slices/ 003722_03_01_417.png\n",
      "/home2/potd0000/project/Key_slices/ 003722_03_01_480.png\n",
      "/home2/potd0000/project/Key_slices/ 003723_02_03_509.png\n",
      "/home2/potd0000/project/Key_slices/ 003723_03_01_056.png\n",
      "/home2/potd0000/project/Key_slices/ 003723_03_01_100.png\n",
      "/home2/potd0000/project/Key_slices/ 003730_01_03_224.png\n",
      "/home2/potd0000/project/Key_slices/ 003730_01_03_229.png\n",
      "/home2/potd0000/project/Key_slices/ 003877_01_02_473.png\n",
      "/home2/potd0000/project/Key_slices/ 003882_02_02_155.png\n",
      "/home2/potd0000/project/Key_slices/ 003980_01_02_254.png\n",
      "/home2/potd0000/project/Key_slices/ 004000_01_01_203.png\n",
      "/home2/potd0000/project/Key_slices/ 004000_02_01_175.png\n",
      "/home2/potd0000/project/Key_slices/ 004003_01_01_054.png\n",
      "/home2/potd0000/project/Key_slices/ 004033_01_01_503.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_153.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_366.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_401.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_337.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_390.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_530.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_478.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_521.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_562.png\n",
      "/home2/potd0000/project/Key_slices/ 004034_01_02_534.png\n",
      "/home2/potd0000/project/Key_slices/ 004048_01_02_052.png\n",
      "/home2/potd0000/project/Key_slices/ 004048_01_02_093.png\n",
      "/home2/potd0000/project/Key_slices/ 004083_01_02_509.png\n",
      "/home2/potd0000/project/Key_slices/ 004132_08_01_202.png\n",
      "/home2/potd0000/project/Key_slices/ 004188_01_01_507.png\n",
      "/home2/potd0000/project/Key_slices/ 004367_01_02_236.png\n",
      "/home2/potd0000/project/Key_slices/ 004367_01_02_466.png\n",
      "/home2/potd0000/project/Key_slices/ 004416_01_01_103.png\n",
      "/home2/potd0000/project/Key_slices/ 004416_01_01_118.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38, 512, 512, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_image_data_list = []\n",
    "\n",
    "for names in yolo_test_bone_ins:\n",
    "    test_image_data_list.extend(Image_directory(directory, names))\n",
    "input_test_image = np.array(test_image_data_list)\n",
    "input_test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('yolo_bone_input_test_image_data', input_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_bone_input_test_image_saved = np.load('yolo_bone_input_test_image_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = yolo_bone_input_train_image_saved\n",
    "outs = np.array(yolo_train_bone_outs)\n",
    "ins_validation = yolo_bone_input_val_image_saved\n",
    "outs_validation = np.array(yolo_val_bone_outs)\n",
    "ins_test = yolo_bone_input_test_image_saved\n",
    "outs_test = np.array(yolo_test_bone_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing Network\n",
    "\n",
    "#I am using three convolution layers with 100 filters.\n",
    "#I am using three convolution layers with 200 filters.\n",
    "#I am using three convolution layers with 300 filters.\n",
    "#I am using three convolution layers with 500 filters.\n",
    "#I am using regularization with value 0\n",
    "#To bring down the number of parameters, I am using 1 x 1 strides in two Maxpooling layers.\n",
    "\n",
    "def construct_model(input_shape, lambda_regularization = 0):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(filters = 100,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 2,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C0'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size = (3, 3), strides = (1, 1), name = 'C1'))\n",
    "    \n",
    "    model.add(Convolution2D(filters = 100,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C2'))\n",
    "    \n",
    "    model.add(Convolution2D(filters = 100,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C3'))\n",
    "    \n",
    "    model.add(Convolution2D(filters = 200,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 2,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C4'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size = (3, 3), strides = (1, 1), name = 'C5'))\n",
    "    \n",
    "    model.add(Convolution2D(filters = 200,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C6'))\n",
    "\n",
    "    model.add(Convolution2D(filters = 200,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C7'))\n",
    "\n",
    "    model.add(Convolution2D(filters = 300,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 2,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C8'))\n",
    "\n",
    "    model.add(Convolution2D(filters = 300,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (5, 5),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C9'))\n",
    "\n",
    "    model.add(Convolution2D(filters = 300,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C10'))\n",
    "    \n",
    "    model.add(Convolution2D(filters = 300,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (3, 3),\n",
    "                           strides = 1,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'elu',\n",
    "                           name = 'C11'))\n",
    "        \n",
    "    model.add(Convolution2D(filters = 5,\n",
    "                           input_shape = input_shape,\n",
    "                           kernel_size = (1, 1),\n",
    "                           strides = 2,\n",
    "                           padding = 'same',\n",
    "                           use_bias = True,\n",
    "                           kernel_initializer = 'random_uniform',\n",
    "                           bias_initializer = 'random_uniform',\n",
    "                           kernel_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           bias_regularizer = keras.regularizers.l2(lambda_regularization),\n",
    "                           activation = 'softmax',\n",
    "                           name = 'output'))\n",
    "        \n",
    "    \n",
    "    # The optimizer determines how the gradient descent is to be done\n",
    "    opt = keras.optimizers.Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999, \n",
    "                            epsilon = None, decay = 0.0, amsgrad = False)\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = opt, \n",
    "                  metrics = ['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C0 (Conv2D)                  (None, 256, 256, 100)     2800      \n",
      "_________________________________________________________________\n",
      "C1 (MaxPooling2D)            (None, 254, 254, 100)     0         \n",
      "_________________________________________________________________\n",
      "C2 (Conv2D)                  (None, 254, 254, 100)     90100     \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 254, 254, 100)     90100     \n",
      "_________________________________________________________________\n",
      "C4 (Conv2D)                  (None, 127, 127, 200)     180200    \n",
      "_________________________________________________________________\n",
      "C5 (MaxPooling2D)            (None, 125, 125, 200)     0         \n",
      "_________________________________________________________________\n",
      "C6 (Conv2D)                  (None, 125, 125, 200)     360200    \n",
      "_________________________________________________________________\n",
      "C7 (Conv2D)                  (None, 125, 125, 200)     360200    \n",
      "_________________________________________________________________\n",
      "C8 (Conv2D)                  (None, 63, 63, 300)       540300    \n",
      "_________________________________________________________________\n",
      "C9 (Conv2D)                  (None, 63, 63, 300)       2250300   \n",
      "_________________________________________________________________\n",
      "C10 (Conv2D)                 (None, 63, 63, 300)       810300    \n",
      "_________________________________________________________________\n",
      "C11 (Conv2D)                 (None, 63, 63, 300)       810300    \n",
      "_________________________________________________________________\n",
      "output (Conv2D)              (None, 32, 32, 5)         1505      \n",
      "=================================================================\n",
      "Total params: 5,496,305\n",
      "Trainable params: 5,496,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = construct_model(ins.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_set_generator(ins, outs, batch_size = 10,\n",
    "                      input_name = 'input_input', \n",
    "                      output_name = 'output'):\n",
    "    while True:\n",
    "        example_indices = random.choices(range(ins.shape[0]), k=batch_size)\n",
    "        yield({input_name: ins[example_indices,:,:,:]},\n",
    "             {output_name: outs[example_indices]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 4/18 [=====>........................] - ETA: 28:20 - loss: 0.2519 - acc: 0.9119"
     ]
    }
   ],
   "source": [
    "generator = training_set_generator(ins,outs, batch_size = 10, \n",
    "                                  input_name = 'C0_input')\n",
    "\n",
    "#Stopping criteria for epoch termination with patience = 10\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                               min_delta = 0, patience = 10, \n",
    "                                               verbose = 0, mode = 'auto', \n",
    "                                               baseline = None, \n",
    "                                               restore_best_weights = True)\n",
    "\n",
    "#Total training set has 172 images and batch size is 10.\n",
    "#Hence 18 steps per epoch will cover entire training dataset.\n",
    "model.fit_generator(generator, epochs = 10, steps_per_epoch = 18, \n",
    "                    validation_data=(ins_validation, outs_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('yolo_model_bhairav-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('yolo_model_bhairav-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(ins_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.17996570e-02, 3.58160995e-02, 3.45983021e-02, 1.47575989e-01,\n",
       "         1.23508200e-01],\n",
       "        [5.53203933e-03, 3.23418435e-03, 4.56377584e-03, 3.42267789e-02,\n",
       "         3.11615486e-02],\n",
       "        [3.96712078e-03, 2.30848766e-03, 3.17956414e-03, 2.51502469e-02,\n",
       "         2.68612951e-02],\n",
       "        ...,\n",
       "        [3.96324322e-03, 2.30699033e-03, 3.18264705e-03, 2.51875278e-02,\n",
       "         2.68876292e-02],\n",
       "        [5.41210035e-03, 3.54228611e-03, 4.40082140e-03, 2.79009622e-02,\n",
       "         3.22699733e-02],\n",
       "        [5.20220175e-02, 3.44998278e-02, 4.94083129e-02, 8.97093862e-02,\n",
       "         1.00782409e-01]],\n",
       "\n",
       "       [[5.37871290e-03, 4.56834212e-03, 3.79505754e-03, 3.41265686e-02,\n",
       "         2.83698626e-02],\n",
       "        [1.13858907e-04, 6.76684140e-05, 7.81247363e-05, 2.60124728e-03,\n",
       "         2.43295357e-03],\n",
       "        [6.30896466e-05, 3.75346171e-05, 3.92024813e-05, 1.59033609e-03,\n",
       "         1.82374823e-03],\n",
       "        ...,\n",
       "        [6.19839630e-05, 3.72336908e-05, 3.92834263e-05, 1.65177754e-03,\n",
       "         1.85025868e-03],\n",
       "        [1.01851518e-04, 7.32063781e-05, 6.90606976e-05, 1.92172802e-03,\n",
       "         2.68124603e-03],\n",
       "        [4.78133140e-03, 3.33868689e-03, 4.06053476e-03, 2.02455707e-02,\n",
       "         2.03528423e-02]],\n",
       "\n",
       "       [[3.87352332e-03, 3.76219023e-03, 2.62134755e-03, 3.00534237e-02,\n",
       "         2.24099122e-02],\n",
       "        [6.42284067e-05, 4.52155437e-05, 3.94255912e-05, 2.02486408e-03,\n",
       "         1.58787135e-03],\n",
       "        [3.64133375e-05, 2.50458343e-05, 1.97574973e-05, 1.34526065e-03,\n",
       "         1.24068488e-03],\n",
       "        ...,\n",
       "        [3.54450713e-05, 2.49125296e-05, 1.94840341e-05, 1.44132436e-03,\n",
       "         1.27669889e-03],\n",
       "        [5.76209823e-05, 4.80878334e-05, 3.50396585e-05, 1.60632143e-03,\n",
       "         1.76659506e-03],\n",
       "        [3.47387325e-03, 2.56516808e-03, 2.63619726e-03, 1.81456301e-02,\n",
       "         1.50630390e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.87045741e-03, 3.75901721e-03, 2.62287655e-03, 3.00899521e-02,\n",
       "         2.24236548e-02],\n",
       "        [6.38275596e-05, 4.45356745e-05, 3.96509167e-05, 2.05522566e-03,\n",
       "         1.60636124e-03],\n",
       "        [3.63253457e-05, 2.44830026e-05, 1.96968449e-05, 1.38055719e-03,\n",
       "         1.24450249e-03],\n",
       "        ...,\n",
       "        [3.64244515e-05, 2.48434189e-05, 1.97335830e-05, 1.39483996e-03,\n",
       "         1.27752055e-03],\n",
       "        [5.81453132e-05, 4.78574912e-05, 3.50626869e-05, 1.57169509e-03,\n",
       "         1.75314920e-03],\n",
       "        [3.47336498e-03, 2.56533991e-03, 2.63580866e-03, 1.81397293e-02,\n",
       "         1.50610665e-02]],\n",
       "\n",
       "       [[5.59902657e-03, 5.93113946e-03, 3.66506330e-03, 3.24277654e-02,\n",
       "         2.68158205e-02],\n",
       "        [1.11023510e-04, 9.63976854e-05, 7.42849224e-05, 2.78664473e-03,\n",
       "         2.27081869e-03],\n",
       "        [6.12357035e-05, 5.36482657e-05, 3.72851755e-05, 1.80717034e-03,\n",
       "         1.74113864e-03],\n",
       "        ...,\n",
       "        [6.11388459e-05, 5.36942243e-05, 3.72553586e-05, 1.80796371e-03,\n",
       "         1.73486362e-03],\n",
       "        [9.83946084e-05, 9.85452280e-05, 6.88997316e-05, 2.26003234e-03,\n",
       "         2.53333477e-03],\n",
       "        [4.61481977e-03, 3.86610092e-03, 4.04605735e-03, 2.47156601e-02,\n",
       "         2.03927308e-02]],\n",
       "\n",
       "       [[5.11451103e-02, 5.31781428e-02, 4.08338122e-02, 8.95287916e-02,\n",
       "         9.88775641e-02],\n",
       "        [5.12721343e-03, 4.84531978e-03, 4.28321864e-03, 2.20796634e-02,\n",
       "         2.35454887e-02],\n",
       "        [3.58224590e-03, 3.24599608e-03, 2.74167839e-03, 1.82019286e-02,\n",
       "         1.94004215e-02],\n",
       "        ...,\n",
       "        [3.58162657e-03, 3.24582309e-03, 2.74145557e-03, 1.82002075e-02,\n",
       "         1.94008015e-02],\n",
       "        [4.56637377e-03, 4.45548911e-03, 3.89062380e-03, 2.12552175e-02,\n",
       "         2.51524169e-02],\n",
       "        [4.08417471e-02, 3.52236293e-02, 3.65512297e-02, 1.05899513e-01,\n",
       "         8.04963633e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        ...,\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062]],\n",
       "\n",
       "       [[0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        ...,\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062]],\n",
       "\n",
       "       [[0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        ...,\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        ...,\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062]],\n",
       "\n",
       "       [[0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        ...,\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062]],\n",
       "\n",
       "       [[0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        ...,\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062],\n",
       "        [0.11914062, 0.11914062, 0.11914062]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
